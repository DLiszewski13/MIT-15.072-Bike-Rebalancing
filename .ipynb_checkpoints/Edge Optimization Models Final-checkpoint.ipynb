{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore all the bs below, used it to build my stochastic models. I'll let you know when the important stuff begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>start.time.interval</th><th>start_area</th><th>end_area</th><th>dep_flow</th><th>hourly.dep.flow.total</th><th>hourly.dep.flow.pct</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>1,800,000 rows × 8 columns (omitted printing of 2 columns)</p><tr><th>1</th><td>2019-09-01 00:00:00</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>2</th><td>2019-09-01 00:00:00</td><td>1</td><td>2</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>3</th><td>2019-09-01 00:00:00</td><td>1</td><td>3</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>4</th><td>2019-09-01 00:00:00</td><td>1</td><td>4</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>5</th><td>2019-09-01 00:00:00</td><td>1</td><td>5</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>6</th><td>2019-09-01 00:00:00</td><td>1</td><td>6</td><td>1</td><td>3</td><td>0.333333</td></tr><tr><th>7</th><td>2019-09-01 00:00:00</td><td>1</td><td>7</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>8</th><td>2019-09-01 00:00:00</td><td>1</td><td>8</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>9</th><td>2019-09-01 00:00:00</td><td>1</td><td>9</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>10</th><td>2019-09-01 00:00:00</td><td>1</td><td>10</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>11</th><td>2019-09-01 00:00:00</td><td>1</td><td>11</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>12</th><td>2019-09-01 00:00:00</td><td>1</td><td>12</td><td>1</td><td>3</td><td>0.333333</td></tr><tr><th>13</th><td>2019-09-01 00:00:00</td><td>1</td><td>13</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>14</th><td>2019-09-01 00:00:00</td><td>1</td><td>14</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>15</th><td>2019-09-01 00:00:00</td><td>1</td><td>15</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>16</th><td>2019-09-01 00:00:00</td><td>1</td><td>16</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>17</th><td>2019-09-01 00:00:00</td><td>1</td><td>17</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>18</th><td>2019-09-01 00:00:00</td><td>1</td><td>18</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>19</th><td>2019-09-01 00:00:00</td><td>1</td><td>19</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>20</th><td>2019-09-01 00:00:00</td><td>1</td><td>20</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>21</th><td>2019-09-01 00:00:00</td><td>1</td><td>21</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>22</th><td>2019-09-01 00:00:00</td><td>1</td><td>22</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>23</th><td>2019-09-01 00:00:00</td><td>1</td><td>23</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>24</th><td>2019-09-01 00:00:00</td><td>1</td><td>24</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>25</th><td>2019-09-01 00:00:00</td><td>1</td><td>25</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>26</th><td>2019-09-01 00:00:00</td><td>1</td><td>26</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>27</th><td>2019-09-01 00:00:00</td><td>1</td><td>27</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>28</th><td>2019-09-01 00:00:00</td><td>1</td><td>28</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>29</th><td>2019-09-01 00:00:00</td><td>1</td><td>29</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>30</th><td>2019-09-01 00:00:00</td><td>1</td><td>30</td><td>0</td><td>0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& start.time.interval & start\\_area & end\\_area & dep\\_flow & hourly.dep.flow.total & hourly.dep.flow.pct & \\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & Int64 & Int64 & Int64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2019-09-01 00:00:00 & 1 & 1 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 2019-09-01 00:00:00 & 1 & 2 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 2019-09-01 00:00:00 & 1 & 3 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 2019-09-01 00:00:00 & 1 & 4 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 2019-09-01 00:00:00 & 1 & 5 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 2019-09-01 00:00:00 & 1 & 6 & 1 & 3 & 0.333333 & $\\dots$ \\\\\n",
       "\t7 & 2019-09-01 00:00:00 & 1 & 7 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 2019-09-01 00:00:00 & 1 & 8 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 2019-09-01 00:00:00 & 1 & 9 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 2019-09-01 00:00:00 & 1 & 10 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 2019-09-01 00:00:00 & 1 & 11 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 2019-09-01 00:00:00 & 1 & 12 & 1 & 3 & 0.333333 & $\\dots$ \\\\\n",
       "\t13 & 2019-09-01 00:00:00 & 1 & 13 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 2019-09-01 00:00:00 & 1 & 14 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 2019-09-01 00:00:00 & 1 & 15 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 2019-09-01 00:00:00 & 1 & 16 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 2019-09-01 00:00:00 & 1 & 17 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 2019-09-01 00:00:00 & 1 & 18 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 2019-09-01 00:00:00 & 1 & 19 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 2019-09-01 00:00:00 & 1 & 20 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 2019-09-01 00:00:00 & 1 & 21 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 2019-09-01 00:00:00 & 1 & 22 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 2019-09-01 00:00:00 & 1 & 23 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 2019-09-01 00:00:00 & 1 & 24 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 2019-09-01 00:00:00 & 1 & 25 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 2019-09-01 00:00:00 & 1 & 26 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 2019-09-01 00:00:00 & 1 & 27 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 2019-09-01 00:00:00 & 1 & 28 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 2019-09-01 00:00:00 & 1 & 29 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 2019-09-01 00:00:00 & 1 & 30 & 0 & 0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1800000×8 DataFrame. Omitted printing of 4 columns\n",
       "│ Row     │ start.time.interval │ start_area │ end_area │ dep_flow │\n",
       "│         │ \u001b[90mString\u001b[39m              │ \u001b[90mInt64\u001b[39m      │ \u001b[90mInt64\u001b[39m    │ \u001b[90mInt64\u001b[39m    │\n",
       "├─────────┼─────────────────────┼────────────┼──────────┼──────────┤\n",
       "│ 1       │ 2019-09-01 00:00:00 │ 1          │ 1        │ 0        │\n",
       "│ 2       │ 2019-09-01 00:00:00 │ 1          │ 2        │ 0        │\n",
       "│ 3       │ 2019-09-01 00:00:00 │ 1          │ 3        │ 0        │\n",
       "│ 4       │ 2019-09-01 00:00:00 │ 1          │ 4        │ 0        │\n",
       "│ 5       │ 2019-09-01 00:00:00 │ 1          │ 5        │ 0        │\n",
       "│ 6       │ 2019-09-01 00:00:00 │ 1          │ 6        │ 1        │\n",
       "│ 7       │ 2019-09-01 00:00:00 │ 1          │ 7        │ 0        │\n",
       "│ 8       │ 2019-09-01 00:00:00 │ 1          │ 8        │ 0        │\n",
       "│ 9       │ 2019-09-01 00:00:00 │ 1          │ 9        │ 0        │\n",
       "│ 10      │ 2019-09-01 00:00:00 │ 1          │ 10       │ 0        │\n",
       "⋮\n",
       "│ 1799990 │ 2019-09-30 23:00:00 │ 50         │ 40       │ 0        │\n",
       "│ 1799991 │ 2019-09-30 23:00:00 │ 50         │ 41       │ 0        │\n",
       "│ 1799992 │ 2019-09-30 23:00:00 │ 50         │ 42       │ 0        │\n",
       "│ 1799993 │ 2019-09-30 23:00:00 │ 50         │ 43       │ 0        │\n",
       "│ 1799994 │ 2019-09-30 23:00:00 │ 50         │ 44       │ 0        │\n",
       "│ 1799995 │ 2019-09-30 23:00:00 │ 50         │ 45       │ 0        │\n",
       "│ 1799996 │ 2019-09-30 23:00:00 │ 50         │ 46       │ 0        │\n",
       "│ 1799997 │ 2019-09-30 23:00:00 │ 50         │ 47       │ 0        │\n",
       "│ 1799998 │ 2019-09-30 23:00:00 │ 50         │ 48       │ 0        │\n",
       "│ 1799999 │ 2019-09-30 23:00:00 │ 50         │ 49       │ 0        │\n",
       "│ 1800000 │ 2019-09-30 23:00:00 │ 50         │ 50       │ 0        │"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = CSV.read(\"sept19_filter_agg_scen1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stations = Set(unique(data1[!,2]))\n",
    "end_stations = Set(unique(data1[!,3]))\n",
    "stations = collect(union(start_stations,end_stations))\n",
    "time_intervals = unique(data1[!,8])\n",
    "days = unique(data1[!,7]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sizes \n",
    "# m = total number of start station clusters\n",
    "m= size(stations,1)\n",
    "# n = total number of time windows\n",
    "n = size(time_intervals,1)\n",
    "# o = total number of days\n",
    "o = size(days,1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ride = 1.15\n",
    "c_bike = 345;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimize_distribution (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function optimize_distribution(data)\n",
    "    #initialize model\n",
    "    mod = Model(solver = GurobiSolver())\n",
    "\n",
    "    #decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o] >= 0,Int)\n",
    "\n",
    "    #objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o))\n",
    "\n",
    "\n",
    "    #constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o],x[i,t,l] - sum(d[i,j,t,l] for j=1:m) + sum(d[j,i,t,l] for j=1:m)-x[i,t+1,l]==0)\n",
    "    @constraint(mod,[d=1:o], sum(x[i,1,d] for i=1:m) == sum(x[i,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data,1)],d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]] <= data[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o],d[i,i,t,l]==0)\n",
    "    @constraint(mod,r_ride*sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o) - c_bike*sum(x[i,1,1] for i=1:m) >= -200000)\n",
    "\n",
    "\n",
    "\n",
    "    #solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    return sum(getvalue(x)[:,1,1]),getvalue(d),getobjectivevalue(mod)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 1870531 rows, 1836000 columns and 7088950 nonzeros\n",
      "Model fingerprint: 0x8997650e\n",
      "Variable types: 36000 continuous, 1800000 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 2e+05]\n",
      "Found heuristic solution: objective 1463.0000000\n",
      "Presolve removed 1852443 rows and 1746517 columns (presolve time = 5s) ...\n",
      "Presolve removed 1852443 rows and 1746528 columns\n",
      "Presolve time: 8.84s\n",
      "Presolved: 18088 rows, 89472 columns, 249573 nonzeros\n",
      "Variable types: 18058 continuous, 71414 integer (53421 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.4630000e+03   0.000000e+00   5.741041e+05     10s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 1.005090e+05, 7162 iterations, 0.28 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    100509.00000 100509.000  0.00%     -   10s\n",
      "\n",
      "Explored 0 nodes (7162 simplex iterations) in 10.45 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 100509 1463 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.005090000000e+05, best bound 1.005090000000e+05, gap 0.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(564.0, [-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 1.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0], 100509.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_distribution(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_distribution (generic function with 1 method)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function baseline_distribution(min_bikes,data)\n",
    "    uniform_dist = round(min_bikes/m)\n",
    "    mod = Model(solver = GurobiSolver())\n",
    "\n",
    "    #decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,l=1:o]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o] >= 0)\n",
    "\n",
    "    #objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o))\n",
    "\n",
    "\n",
    "    #constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o],x[i,t,l] - sum(d[i,j,t,l] for j=1:m) + sum(d[j,i,t,l] for j=1:m)-x[i,t+1,l]==0)\n",
    "    @constraint(mod,[d=1:o], sum(x[i,1,d] for i=1:m) == sum(x[i,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data,1)],d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]] <= data[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o],d[i,i,t,l]==0)\n",
    "    @constraint(mod,[i=1:m,d=1:o],x[i,1,d]==uniform_dist)\n",
    "#     @constraint(mod,r_ride*sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o) - c_bike*sum(x[i,1,1] for i=1:m) >= -200000)\n",
    "\n",
    "    status = solve(mod)\n",
    "    \n",
    "    return getvalue(d)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything Above is Useless, The Real Shit Starts from Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions to run this baby:\n",
    "1. Make sure your files are named properly and that you have the csv files for all 4 scenarios for the months you want to run the model for. The file naming convention is \"mmmmyy_filter_agg_scenx.csv\" .For example, \"sept19_filter_agg_scen1.csv\"\n",
    "2. Every csv file should have the following columns with this exact naming convention: \"start_area\", \"end_area\", \"dep_flow\",\"Hour\"(0-23),\"Day\"(1-30/31).\n",
    "3. Run the functions below and then call the compute_everything function. The arguments to this function are \n",
    "    - a list of months you want to compute everything. For example - [\"sept19\",\"may18\",\"oct20\"]. Every month in this list should match the way the month is spelt in the dataset. \n",
    "    - The acceptable total loss per month (eg 200000)\n",
    "    - Operational Revenue - Operational costs (we discussed this number to be 1.15)\n",
    "    - Fixed cost of a bike (we discussed this to be 200)\n",
    "    - example call of the function - main_result = compute_everything([\"sept19\"],200000,1.15,200)\n",
    "4. The function ouputs the following:\n",
    "    - A CSV file with the optimal number of bikes per station per day for each month in the list of months\n",
    "    - A CSV file with the optimal model allowed flows for Scenario 1.\n",
    "    - A dataframe with the following information for each month (each row of the dataframe corresponds to one month in the list of months: Minimum Number of Bikes from the optimal model, Number of missed rides for the optimal and baseline scenarios, number of met rides for the optimal and baseline scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Gurobi, DataFrames, CSV, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_missed_rides (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_missed_rides(data,d)\n",
    "    missed_rides = [(data[i,:dep_flow]-d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]])\n",
    "    for i=1:size(data,1)]\n",
    "    return sum(missed_rides)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_model (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### stochastic optimization model\n",
    "function stochastic_model(data1,data2,data3,data4,acceptable_loss,r_ride,c_bike)\n",
    "    \n",
    "    # m = total number of start station clusters\n",
    "    m= size(unique(data1[!,:start_area]),1)\n",
    "    # n = total number of time windows\n",
    "    n = size(unique(data1[!,:Hour]),1)\n",
    "    # o = total number of days\n",
    "    o = size(unique(data1[!,:Day]),1)\n",
    "    \n",
    "    #1. initialize model\n",
    "    \n",
    "    mod = Model(solver = GurobiSolver())\n",
    "    \n",
    "    #2. decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o,s=1:4]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o,s=1:4] >= 0,Int)\n",
    "    \n",
    "    #3. objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4)\n",
    "    \n",
    "    \n",
    "    #4. constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o,s=1:4],x[i,t,l,s] - sum(d[i,j,t,l,s] for j=1:m) + sum(d[j,i,t,l,s] for j=1:m)-x[i,t+1,l,s]==0)\n",
    "    @constraint(mod,[d=1:o,s=1:4], sum(x[i,1,d,s] for i=1:m) == sum(x[i,1,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data1,1)],d[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day],1] <= data1[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data2,1)],d[data2[i,:start_area],data2[i,:end_area],data2[i,:Hour]+1,data2[i,:Day],2] <= data2[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data3,1)],d[data3[i,:start_area],data3[i,:end_area],data3[i,:Hour]+1,data3[i,:Day],3] <= data3[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data4,1)],d[data4[i,:start_area],data4[i,:end_area],data4[i,:Hour]+1,data4[i,:Day],4] <= data4[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o,s=1:4],d[i,i,t,l,s]==0)\n",
    "    @constraint(mod,r_ride*(sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4) - c_bike*sum(x[i,1,1,1] for i=1:m) >= -acceptable_loss)\n",
    "    \n",
    "    #5. solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    #6. Compute missed rides and average it for the 4 scenarios\n",
    "    missed_rides1 = compute_missed_rides(data1,getvalue(d)[:,:,:,:,1])\n",
    "    missed_rides2 = compute_missed_rides(data2,getvalue(d)[:,:,:,:,2])\n",
    "    missed_rides3 = compute_missed_rides(data3,getvalue(d)[:,:,:,:,3])\n",
    "    missed_rides4 = compute_missed_rides(data4,getvalue(d)[:,:,:,:,4])\n",
    "    avg_missed_rides = (missed_rides1+missed_rides2+missed_rides3+missed_rides4)/4\n",
    "    \n",
    "    #7. Compute number of rides met and average it for each scenario\n",
    "    avg_met_rides = getobjectivevalue(mod)\n",
    "    \n",
    "    #8. Input number of bikes per station per day into a dataframe (only for scenario 1)\n",
    "    bikes = getvalue(x)[:,1,:,1]\n",
    "    x_df = DataFrame(Station=Int[],Day=Int[],Num_Bikes=Int[])\n",
    "    for i=1:m\n",
    "        for j=1:o\n",
    "            push!(x_df,[i,j,bikes[i,j]])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    \n",
    "    #9. Input allowed flows from scenario 1 into its dataframe (data1)\n",
    "    flows= getvalue(d)[:,:,:,:,1]\n",
    "    allowed_flows = []\n",
    "    for i in 1:size(data1,1)\n",
    "        append!(allowed_flows,flows[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day]])\n",
    "    end\n",
    "    data1[:allowed_flows] = allowed_flows\n",
    "    final_flows_data = data1[:,[2,3,4,7,8,9]]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #10. return\n",
    "    return sum(getvalue(x)[:,1,1,1]),avg_missed_rides,avg_met_rides,x_df,final_flows_data\n",
    "    \n",
    "end\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_baseline (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stochastic_baseline(data1,data2,data3,data4,min_bikes,r_ride,c_bike)\n",
    "    # m = total number of start station clusters\n",
    "    m= size(unique(data1[!,:start_area]),1)\n",
    "    # n = total number of time windows\n",
    "    n = size(unique(data1[!,:Hour]),1)\n",
    "    # o = total number of days\n",
    "    o = size(unique(data1[!,:Day]),1)\n",
    "    \n",
    "    #1. uniform_dist = uniformly distributed number of bikes at each station\n",
    "    uniform_dist = round(min_bikes/m)\n",
    "    \n",
    "    #2. initialize model\n",
    "    \n",
    "    mod = Model(solver = GurobiSolver())\n",
    "    \n",
    "    #3. decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o,s=1:4]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o,s=1:4] >= 0,Int)\n",
    "    \n",
    "    #4. objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4)\n",
    "    \n",
    "    \n",
    "    #5. constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o,s=1:4],x[i,t,l,s] - sum(d[i,j,t,l,s] for j=1:m) + sum(d[j,i,t,l,s] for j=1:m)-x[i,t+1,l,s]==0)\n",
    "    @constraint(mod,[d=1:o,s=1:4], sum(x[i,1,d,s] for i=1:m) == sum(x[i,1,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data1,1)],d[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day],1] <= data1[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data2,1)],d[data2[i,:start_area],data2[i,:end_area],data2[i,:Hour]+1,data2[i,:Day],2] <= data2[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data3,1)],d[data3[i,:start_area],data3[i,:end_area],data3[i,:Hour]+1,data3[i,:Day],3] <= data3[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data4,1)],d[data4[i,:start_area],data4[i,:end_area],data4[i,:Hour]+1,data4[i,:Day],4] <= data4[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o,s=1:4],d[i,i,t,l,s]==0)\n",
    "    @constraint(mod,[i=1:m,d=1:o,s=1:4],x[i,1,d,s]==uniform_dist)\n",
    "    \n",
    "    #6. solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    #7. Compute missed rides and average it for the 4 scenarios\n",
    "    missed_rides1 = compute_missed_rides(data1,getvalue(d)[:,:,:,:,1])\n",
    "    missed_rides2 = compute_missed_rides(data2,getvalue(d)[:,:,:,:,2])\n",
    "    missed_rides3 = compute_missed_rides(data3,getvalue(d)[:,:,:,:,3])\n",
    "    missed_rides4 = compute_missed_rides(data4,getvalue(d)[:,:,:,:,4])\n",
    "    avg_missed_rides = (missed_rides1+missed_rides2+missed_rides3+missed_rides4)/4\n",
    "    \n",
    "    #8. Compute number of rides met and average it for each scenario\n",
    "    avg_met_rides = getobjectivevalue(mod)\n",
    "   \n",
    "    \n",
    "    #9. return\n",
    "    return avg_missed_rides,avg_met_rides\n",
    "    \n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function That Computes Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_everything (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_everything(month_list,acceptable_loss,r_ride,c_bike)\n",
    "    main_df = DataFrame(Month=String[],Min_Bikes=Int[],Missed_Optimal=Int[],\n",
    "    Missed_Baseline=Int[],Met_Optimal=Int[],Met_Baseline=Int[])\n",
    "    for i in month_list\n",
    "        \n",
    "        #read in datasets for the 4 scenarios\n",
    "        \n",
    "        data1 = CSV.read(\"$i\"*\"_filter_agg_scen1.csv\")\n",
    "        data2 = CSV.read(\"$i\"*\"_filter_agg_scen2.csv\")\n",
    "        data3 = CSV.read(\"$i\"*\"_filter_agg_scen3.csv\")\n",
    "        data4 = CSV.read(\"$i\"*\"_filter_agg_scen4.csv\")\n",
    "        \n",
    "        #define sizes - do it for one dataset because its the same for all 4 scenarios\n",
    "        \n",
    "        # m = total number of start station clusters\n",
    "        m= size(unique(data1[!,:start_area]),1)\n",
    "        # n = total number of time windows\n",
    "        n = size(unique(data1[!,:Hour]),1)\n",
    "        # o = total number of days\n",
    "        o = size(unique(data1[!,:Day]),1)\n",
    "        \n",
    "        #run optimal model and get outputs\n",
    "        optimal_solution = stochastic_model(data1,data2,data3,data4,acceptable_loss,r_ride,c_bike)\n",
    "        Min_Bikes = optimal_solution[1]\n",
    "        Missed_Optimal = optimal_solution[2]\n",
    "        Met_Optimal = optimal_solution[3]\n",
    "        CSV.write(\"$i\"*\"_bike_distribution.csv\",optimal_solution[4])\n",
    "        CSV.write(\"$i\"*\"_flows.csv\",optimal_solution[5])\n",
    "        \n",
    "        #run baseline model and get outputs\n",
    "        baseline_solution = stochastic_baseline(data1,data2,data3,data4,Min_Bikes,r_ride,c_bike)\n",
    "        Missed_Baseline = baseline_solution[1]\n",
    "        Met_Baseline = baseline_solution[2]\n",
    "        \n",
    "        \n",
    "        #push values into main dataframe\n",
    "        push!(main_df,[i,Min_Bikes,\n",
    "                round(Missed_Optimal),round(Missed_Baseline),round(Met_Optimal),round(Met_Baseline)])\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return main_df\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 7482121 rows, 7344000 columns and 28355950 nonzeros\n",
      "Model fingerprint: 0x98edc3a8\n",
      "Variable types: 144000 continuous, 7200000 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-01, 2e+02]\n",
      "  Objective range  [2e-01, 2e-01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 2e+05]\n",
      "Found heuristic solution: objective 1266.5000000\n",
      "Presolve removed 7346981 rows and 150000 columns (presolve time = 11s) ...\n",
      "Presolve removed 7390998 rows and 7003285 columns (presolve time = 15s) ...\n",
      "Presolve removed 7409470 rows and 7022926 columns (presolve time = 21s) ...\n",
      "Presolve removed 7415431 rows and 7029083 columns (presolve time = 25s) ...\n",
      "Presolve removed 7415435 rows and 7029128 columns (presolve time = 31s) ...\n",
      "Presolve removed 7415435 rows and 7029128 columns (presolve time = 39s) ...\n",
      "Presolve removed 7415434 rows and 7029127 columns\n",
      "Presolve time: 39.28s\n",
      "Presolved: 66687 rows, 314873 columns, 874793 nonzeros\n",
      "Variable types: 66549 continuous, 248324 integer (187648 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.2665000e+03   0.000000e+00   4.989305e+05     47s\n",
      "Concurrent spin time: 0.02s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 8.640975e+04, 25790 iterations, 1.17 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    86409.750000 86409.7500  0.00%     -   47s\n",
      "\n",
      "Explored 0 nodes (25790 simplex iterations) in 48.95 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 86409.8 1266.5 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.640975000000e+04, best bound 8.640975000000e+04, gap 0.0000%\n",
      "Academic license - for non-commercial use only\n",
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 7488120 rows, 7344000 columns and 21161900 nonzeros\n",
      "Model fingerprint: 0xaec89458\n",
      "Variable types: 144000 continuous, 7200000 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-01, 2e-01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 3e+01]\n",
      "Presolve removed 7353100 rows and 156000 columns (presolve time = 9s) ...\n",
      "Presolve removed 7353100 rows and 156000 columns (presolve time = 10s) ...\n",
      "Presolve removed 7415839 rows and 7030000 columns (presolve time = 16s) ...\n",
      "Presolve removed 7438631 rows and 7058131 columns (presolve time = 21s) ...\n",
      "Presolve removed 7444571 rows and 7070937 columns (presolve time = 25s) ...\n",
      "Presolve removed 7444627 rows and 7071314 columns (presolve time = 31s) ...\n",
      "Presolve removed 7487584 rows and 7340150 columns\n",
      "Presolve time: 33.13s\n",
      "Presolved: 536 rows, 3850 columns, 7650 nonzeros\n",
      "Variable types: 0 continuous, 3850 integer (2126 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    8.3930000e+04   3.263750e+02   0.000000e+00     40s\n",
      "     496    8.3887750e+04   0.000000e+00   0.000000e+00     40s\n",
      "\n",
      "Root relaxation: objective 8.388775e+04, 496 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    83887.750000 83887.7500  0.00%     -   39s\n",
      "\n",
      "Explored 0 nodes (496 simplex iterations) in 41.66 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 83887.8 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.388775000000e+04, best bound 8.388775000000e+04, gap 0.0000%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Month</th><th>Min_Bikes</th><th>Missed_Optimal</th><th>Missed_Baseline</th><th>Met_Optimal</th><th>Met_Baseline</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>1 rows × 6 columns</p><tr><th>1</th><td>sept19</td><td>629</td><td>8636</td><td>11158</td><td>86410</td><td>83888</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Month & Min\\_Bikes & Missed\\_Optimal & Missed\\_Baseline & Met\\_Optimal & Met\\_Baseline\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & sept19 & 629 & 8636 & 11158 & 86410 & 83888 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ Month  │ Min_Bikes │ Missed_Optimal │ Missed_Baseline │ Met_Optimal │\n",
       "│     │ \u001b[90mString\u001b[39m │ \u001b[90mInt64\u001b[39m     │ \u001b[90mInt64\u001b[39m          │ \u001b[90mInt64\u001b[39m           │ \u001b[90mInt64\u001b[39m       │\n",
       "├─────┼────────┼───────────┼────────────────┼─────────────────┼─────────────┤\n",
       "│ 1   │ sept19 │ 629       │ 8636           │ 11158           │ 86410       │"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_result = compute_everything([\"sept19\"],200000,1.15,200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
