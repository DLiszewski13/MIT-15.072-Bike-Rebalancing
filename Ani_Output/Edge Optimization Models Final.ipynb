{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ignore all the bs below, used it to build my stochastic models. I'll let you know when the important stuff begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T17:11:49.574000-05:00",
     "start_time": "2020-11-17T22:11:45.659Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: CSV not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: CSV not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[1]:1"
     ]
    }
   ],
   "source": [
    "data1 = CSV.read(\"sept19_filter_agg_scen1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_stations = Set(unique(data1[!,2]))\n",
    "end_stations = Set(unique(data1[!,3]))\n",
    "stations = collect(union(start_stations,end_stations))\n",
    "time_intervals = unique(data1[!,8])\n",
    "days = unique(data1[!,7]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#define sizes \n",
    "# m = total number of start station clusters\n",
    "m= size(stations,1)\n",
    "# n = total number of time windows\n",
    "n = size(time_intervals,1)\n",
    "# o = total number of days\n",
    "o = size(days,1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r_ride = 1.15\n",
    "c_bike = 345;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimize_distribution (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function optimize_distribution(data)\n",
    "    #initialize model\n",
    "    mod = Model(solver = GurobiSolver())\n",
    "\n",
    "    #decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o] >= 0,Int)\n",
    "\n",
    "    #objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o))\n",
    "\n",
    "\n",
    "    #constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o],x[i,t,l] - sum(d[i,j,t,l] for j=1:m) + sum(d[j,i,t,l] for j=1:m)-x[i,t+1,l]==0)\n",
    "    @constraint(mod,[d=1:o], sum(x[i,1,d] for i=1:m) == sum(x[i,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data,1)],d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]] <= data[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o],d[i,i,t,l]==0)\n",
    "    @constraint(mod,r_ride*sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o) - c_bike*sum(x[i,1,1] for i=1:m) >= -200000)\n",
    "\n",
    "\n",
    "    #solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    return sum(getvalue(x)[:,1,1]),getvalue(d),getobjectivevalue(mod)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 1870531 rows, 1836000 columns and 7088950 nonzeros\n",
      "Model fingerprint: 0x8997650e\n",
      "Variable types: 36000 continuous, 1800000 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 2e+05]\n",
      "Found heuristic solution: objective 1463.0000000\n",
      "Presolve removed 1852443 rows and 1746517 columns (presolve time = 5s) ...\n",
      "Presolve removed 1852443 rows and 1746528 columns\n",
      "Presolve time: 8.84s\n",
      "Presolved: 18088 rows, 89472 columns, 249573 nonzeros\n",
      "Variable types: 18058 continuous, 71414 integer (53421 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.4630000e+03   0.000000e+00   5.741041e+05     10s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 1.005090e+05, 7162 iterations, 0.28 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    100509.00000 100509.000  0.00%     -   10s\n",
      "\n",
      "Explored 0 nodes (7162 simplex iterations) in 10.45 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 100509 1463 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.005090000000e+05, best bound 1.005090000000e+05, gap 0.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(564.0, [-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 1.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0], 100509.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_distribution(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_distribution (generic function with 1 method)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function baseline_distribution(min_bikes,data)\n",
    "    uniform_dist = round(min_bikes/m)\n",
    "    mod = Model(solver = GurobiSolver())\n",
    "\n",
    "    #decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,l=1:o]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o] >= 0)\n",
    "\n",
    "    #objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o))\n",
    "\n",
    "\n",
    "    #constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o],x[i,t,l] - sum(d[i,j,t,l] for j=1:m) + sum(d[j,i,t,l] for j=1:m)-x[i,t+1,l]==0)\n",
    "    @constraint(mod,[d=1:o], sum(x[i,1,d] for i=1:m) == sum(x[i,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data,1)],d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]] <= data[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o],d[i,i,t,l]==0)\n",
    "    @constraint(mod,[i=1:m,d=1:o],x[i,1,d]==uniform_dist)\n",
    "#     @constraint(mod,r_ride*sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o) - c_bike*sum(x[i,1,1] for i=1:m) >= -200000)\n",
    "\n",
    "    status = solve(mod)\n",
    "    \n",
    "    return getvalue(d)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything Above is Useless, The Real Shit Starts from Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions to run this baby:\n",
    "1. Make sure your files are named properly and that you have the csv files for all 4 scenarios for the months you want to run the model for. The file naming convention is \"mmmmyy_filter_agg_scenx.csv\" .For example, \"sept19_filter_agg_scen1.csv\"\n",
    "2. Every csv file should have the following columns with this exact naming convention: \"start_area\", \"end_area\", \"dep_flow\",\"Hour\"(0-23),\"Day\"(1-30/31).\n",
    "3. Run the functions below and then call the compute_everything function. The arguments to this function are \n",
    "    - a list of months you want to compute everything. For example - [\"sept19\",\"may18\",\"oct20\"]. Every month in this list should match the way the month is spelt in the dataset. \n",
    "    - The acceptable total loss per month (eg 200000)\n",
    "    - Operational Revenue - Operational costs (we discussed this number to be 1.15)\n",
    "    - Fixed cost of a bike (we discussed this to be 200)\n",
    "    - example call of the function - main_result = compute_everything([\"sept19\"],200000,1.15,200)\n",
    "4. The function ouputs the following:\n",
    "    - A CSV file with the optimal number of bikes per station per day for each month in the list of months\n",
    "    - A CSV file with the optimal model allowed flows for Scenario 1.\n",
    "    - A dataframe with the following information for each month (each row of the dataframe corresponds to one month in the list of months: Minimum Number of Bikes from the optimal model, Number of missed rides for the optimal and baseline scenarios, number of met rides for the optimal and baseline scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T00:23:14.589000-05:00",
     "start_time": "2020-11-18T05:23:00.024Z"
    }
   },
   "outputs": [],
   "source": [
    "using JuMP, Gurobi, DataFrames, CSV, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T00:23:22.168000-05:00",
     "start_time": "2020-11-18T05:23:00.738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_missed_rides (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_missed_rides(data,d)\n",
    "    missed_rides = [(data[i,:dep_flow]-d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]])\n",
    "    for i=1:size(data,1)]\n",
    "    return sum(missed_rides)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T00:35:53.568000-05:00",
     "start_time": "2020-11-18T05:35:53.305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_model (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### stochastic optimization model\n",
    "function stochastic_model(data1,data2,data3,data4,acceptable_loss,r_ride,c_bike)\n",
    "    \n",
    "    # m = total number of start station clusters\n",
    "    m= size(unique(data1[!,:start_area]),1)\n",
    "    # n = total number of time windows\n",
    "    n = size(unique(data1[!,:Hour]),1)\n",
    "    # o = total number of days\n",
    "    o = size(unique(data1[!,:Day]),1)\n",
    "    \n",
    "    #1. initialize model\n",
    "    \n",
    "    mod = Model(solver = GurobiSolver())\n",
    "    \n",
    "    #2. decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o,s=1:4]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o,s=1:4] >= 0,Int)\n",
    "    \n",
    "    #3. objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4)\n",
    "    \n",
    "    #4. constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o,s=1:4],x[i,t,l,s] - sum(d[i,j,t,l,s] for j=1:m) + sum(d[j,i,t,l,s] for j=1:m)-x[i,t+1,l,s]==0)\n",
    "    @constraint(mod,[d=1:o,s=1:4], sum(x[i,1,d,s] for i=1:m) == sum(x[i,1,1,1] for i=1:m))\n",
    "    print(\"Checkpoint1\")\n",
    "    @constraint(mod,[i=1:size(data1,1)],d[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day],1] <= data1[i,:dep_flow])\n",
    "    print(\"Checkpoint2\")\n",
    "    @constraint(mod,[i=1:size(data2,1)],d[data2[i,:start_area],data2[i,:end_area],data2[i,:Hour]+1,data2[i,:Day],2] <= data2[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data3,1)],d[data3[i,:start_area],data3[i,:end_area],data3[i,:Hour]+1,data3[i,:Day],3] <= data3[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data4,1)],d[data4[i,:start_area],data4[i,:end_area],data4[i,:Hour]+1,data4[i,:Day],4] <= data4[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o,s=1:4],d[i,i,t,l,s]==0)\n",
    "    @constraint(mod,r_ride*(sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4) - c_bike*sum(x[i,1,1,1] for i=1:m) >= -acceptable_loss)\n",
    "    \n",
    "    #5. solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    #6. Compute missed rides and average it for the 4 scenarios\n",
    "    missed_rides1 = compute_missed_rides(data1,getvalue(d)[:,:,:,:,1])\n",
    "    missed_rides2 = compute_missed_rides(data2,getvalue(d)[:,:,:,:,2])\n",
    "    missed_rides3 = compute_missed_rides(data3,getvalue(d)[:,:,:,:,3])\n",
    "    missed_rides4 = compute_missed_rides(data4,getvalue(d)[:,:,:,:,4])\n",
    "    avg_missed_rides = (missed_rides1+missed_rides2+missed_rides3+missed_rides4)/4\n",
    "    \n",
    "    #7. Compute number of rides met and average it for each scenario\n",
    "    avg_met_rides = getobjectivevalue(mod)\n",
    "    \n",
    "    #8. Input number of bikes per station per day into a dataframe (only for scenario 1)\n",
    "    bikes = getvalue(x)[:,1,:,1]\n",
    "    x_df = DataFrame(Station=Int[],Day=Int[],Num_Bikes=Int[])\n",
    "    for i=1:m\n",
    "        for j=1:o\n",
    "            push!(x_df,[i,j,bikes[i,j]])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    \n",
    "    #9. Input allowed flows from scenario 1 into its dataframe (data1)\n",
    "    flows= getvalue(d)[:,:,:,:,1]\n",
    "    allowed_flows = []\n",
    "    for i in 1:size(data1,1)\n",
    "        append!(allowed_flows,flows[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day]])\n",
    "    end\n",
    "    data1[:allowed_flows] = allowed_flows\n",
    "    final_flows_data = data1[:,[2,3,4,7,8,9]]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #10. return\n",
    "    return sum(getvalue(x)[:,1,1,1]),avg_missed_rides,avg_met_rides,x_df,final_flows_data\n",
    "    \n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T00:35:54.648000-05:00",
     "start_time": "2020-11-18T05:35:54.403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_baseline (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stochastic_baseline(data1,data2,data3,data4,min_bikes,r_ride,c_bike)\n",
    "    # m = total number of start station clusters\n",
    "    m= size(unique(data1[!,:start_area]),1)\n",
    "    # n = total number of time windows\n",
    "    n = size(unique(data1[!,:Hour]),1)\n",
    "    # o = total number of days\n",
    "    o = size(unique(data1[!,:Day]),1)\n",
    "    \n",
    "    #1. uniform_dist = uniformly distributed number of bikes at each station\n",
    "    uniform_dist = round(min_bikes/m)\n",
    "    \n",
    "    #2. initialize model\n",
    "    \n",
    "    mod = Model(solver = GurobiSolver())\n",
    "    \n",
    "    #3. decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o,s=1:4]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o,s=1:4] >= 0,Int)\n",
    "    \n",
    "    #4. objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4)\n",
    "    \n",
    "    \n",
    "    #5. constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o,s=1:4],x[i,t,l,s] - sum(d[i,j,t,l,s] for j=1:m) + sum(d[j,i,t,l,s] for j=1:m)-x[i,t+1,l,s]==0)\n",
    "    @constraint(mod,[d=1:o,s=1:4], sum(x[i,1,d,s] for i=1:m) == sum(x[i,1,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data1,1)],d[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day],1] <= data1[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data2,1)],d[data2[i,:start_area],data2[i,:end_area],data2[i,:Hour]+1,data2[i,:Day],2] <= data2[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data3,1)],d[data3[i,:start_area],data3[i,:end_area],data3[i,:Hour]+1,data3[i,:Day],3] <= data3[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data4,1)],d[data4[i,:start_area],data4[i,:end_area],data4[i,:Hour]+1,data4[i,:Day],4] <= data4[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o,s=1:4],d[i,i,t,l,s]==0)\n",
    "    @constraint(mod,[i=1:m,d=1:o,s=1:4],x[i,1,d,s]==uniform_dist)\n",
    "    \n",
    "    #6. solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    #7. Compute missed rides and average it for the 4 scenarios\n",
    "    missed_rides1 = compute_missed_rides(data1,getvalue(d)[:,:,:,:,1])\n",
    "    missed_rides2 = compute_missed_rides(data2,getvalue(d)[:,:,:,:,2])\n",
    "    missed_rides3 = compute_missed_rides(data3,getvalue(d)[:,:,:,:,3])\n",
    "    missed_rides4 = compute_missed_rides(data4,getvalue(d)[:,:,:,:,4])\n",
    "    avg_missed_rides = (missed_rides1+missed_rides2+missed_rides3+missed_rides4)/4\n",
    "    \n",
    "    #8. Compute number of rides met and average it for each scenario\n",
    "    avg_met_rides = getobjectivevalue(mod)\n",
    "   \n",
    "    \n",
    "    #9. return\n",
    "    return avg_missed_rides,avg_met_rides\n",
    "    \n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function That Computes Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T00:35:55.531000-05:00",
     "start_time": "2020-11-18T05:35:55.172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_everything (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_everything(month_list,acceptable_loss,r_ride,c_bike)\n",
    "    main_df = DataFrame(Month=String[],Min_Bikes=Int[],Missed_Optimal=Int[],\n",
    "    Missed_Baseline=Int[],Met_Optimal=Int[],Met_Baseline=Int[])\n",
    "    for i in month_list\n",
    "        \n",
    "        #read in datasets for the 4 scenarios\n",
    "        \n",
    "        data1 = CSV.read(\"$i\"*\"_filter_agg_scen1.csv\")\n",
    "        data2 = CSV.read(\"$i\"*\"_filter_agg_scen2.csv\")\n",
    "        data3 = CSV.read(\"$i\"*\"_filter_agg_scen3.csv\")\n",
    "        data4 = CSV.read(\"$i\"*\"_filter_agg_scen4.csv\")\n",
    "        \n",
    "        #define sizes - do it for one dataset because its the same for all 4 scenarios\n",
    "        \n",
    "        # m = total number of start station clusters\n",
    "        m= size(unique(data1[!,:start_area]),1)\n",
    "        # n = total number of time windows\n",
    "        n = size(unique(data1[!,:Hour]),1)\n",
    "        # o = total number of days\n",
    "        o = size(unique(data1[!,:Day]),1)\n",
    "        \n",
    "        #run optimal model and get outputs\n",
    "        optimal_solution = stochastic_model(data1,data2,data3,data4,acceptable_loss,r_ride,c_bike)\n",
    "        Min_Bikes = optimal_solution[1]\n",
    "        Missed_Optimal = optimal_solution[2]\n",
    "        Met_Optimal = optimal_solution[3]\n",
    "#         CSV.write(\"$i\"*\"_bike_distribution.csv\",optimal_solution[4])\n",
    "#         CSV.write(\"$i\"*\"_flows.csv\",optimal_solution[5])\n",
    "        \n",
    "        #run baseline model and get outputs\n",
    "        baseline_solution = stochastic_baseline(data1,data2,data3,data4,Min_Bikes,r_ride,c_bike)\n",
    "        Missed_Baseline = baseline_solution[1]\n",
    "        Met_Baseline = baseline_solution[2]\n",
    "        \n",
    "        \n",
    "        #push values into main dataframe\n",
    "        push!(main_df,[i,Min_Bikes,\n",
    "                round(Missed_Optimal),round(Missed_Baseline),round(Met_Optimal),round(Met_Baseline)])\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return main_df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T00:35:59.282000-05:00",
     "start_time": "2020-11-18T05:35:55.714Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint1"
     ]
    },
    {
     "ename": "BoundsError",
     "evalue": "BoundsError: attempt to access 16×16×24×31×4 Array{Variable,5} at index [1, 17, 1, 1, 1]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 16×16×24×31×4 Array{Variable,5} at index [1, 17, 1, 1, 1]",
      "",
      "Stacktrace:",
      " [1] getindex at ./array.jl:732 [inlined]",
      " [2] macro expansion at /Users/iai/builds/InterpretableAI/SysImgBuilder/.julia/packages/JuMP/I7whV/src/macros.jl:493 [inlined]",
      " [3] stochastic_model(::DataFrame, ::DataFrame, ::DataFrame, ::DataFrame, ::Int64, ::Float64, ::Int64) at ./In[22]:26",
      " [4] compute_everything(::Array{String,1}, ::Int64, ::Float64, ::Int64) at ./In[24]:23",
      " [5] top-level scope at In[25]:1"
     ]
    }
   ],
   "source": [
    "main_result = compute_everything([\"jan15\", \"feb15\", \"mar15\", \"may15\", \"jan16\", \"feb16\", \"mar16\", \"may16\", \"jan17\", \"feb17\", \"mar17\", \"may17\"],200000,1.15,200)\n",
    "CSV.write(\"2015_2016_2017_main_result.csv\",main_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T10:03:02.932000-05:00",
     "start_time": "2020-11-18T15:02:04.227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jan15  ALL GOOD\n",
      "feb15  ALL GOOD\n",
      "mar15  ALL GOOD\n",
      "may15  ALL GOOD\n",
      "jan16  ALL GOOD\n",
      "feb16  ALL GOOD\n",
      "mar16  ALL GOOD\n",
      "may16  ALL GOOD\n",
      "jan17  ALL GOOD\n",
      "feb17  ALL GOOD\n",
      "mar17  ALL GOOD\n",
      "may17  ALL GOOD\n"
     ]
    }
   ],
   "source": [
    "for month in [\"jan15\", \"feb15\", \"mar15\", \"may15\", \"jan16\", \"feb16\", \"mar16\", \"may16\", \"jan17\", \"feb17\", \"mar17\", \"may17\"]\n",
    "    data1 = CSV.read(month*\"_filter_agg_scen1.csv\")\n",
    "    data2 = CSV.read(month*\"_filter_agg_scen2.csv\")\n",
    "    data3 = CSV.read(month*\"_filter_agg_scen3.csv\")\n",
    "    data4 = CSV.read(month*\"_filter_agg_scen4.csv\")\n",
    "    \n",
    "    s1 = size(unique(data1[!,:start_area]),1)\n",
    "    s2 = size(unique(data2[!,:start_area]),1)\n",
    "    s3 = size(unique(data3[!,:start_area]),1)\n",
    "    s4 = size(unique(data4[!,:start_area]),1)\n",
    "    \n",
    "    e1 = size(unique(data1[!,:end_area]),1)\n",
    "    e2 = size(unique(data1[!,:end_area]),1)\n",
    "    e3 = size(unique(data1[!,:end_area]),1)\n",
    "    e4 = size(unique(data1[!,:end_area]),1)\n",
    "    \n",
    "    if s1 == s2 & s1 == s3 & s1 == s4 & s1 == e1 & s1 == e2 & s1 == e3 & s1 == e4\n",
    "        println(month*\"  ALL GOOD\")\n",
    "    else\n",
    "        println(month*\"  NOmT ALL GOOD\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:26:09.643000-05:00",
     "start_time": "2020-11-18T06:26:08.519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = CSV.read(\"jan15\"*\"_filter_agg_scen2.csv\")\n",
    "size(unique(data2[!,:end_area]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:26:11.306000-05:00",
     "start_time": "2020-11-18T06:26:10.441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = CSV.read(\"jan15\"*\"_filter_agg_scen1.csv\")\n",
    "size(unique(data1[!,:end_area]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:26:12.517000-05:00",
     "start_time": "2020-11-18T06:26:11.686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = CSV.read(\"jan15\"*\"_filter_agg_scen3.csv\")\n",
    "size(unique(data3[!,:end_area]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:26:13.073000-05:00",
     "start_time": "2020-11-18T06:26:12.349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = CSV.read(\"jan15\"*\"_filter_agg_scen2.csv\")\n",
    "size(unique(data2[!,:start_area]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T01:26:13.525000-05:00",
     "start_time": "2020-11-18T06:26:13.438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Array{Int64,1}:\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       "  ⋮\n",
       " 39\n",
       " 40\n",
       " 41\n",
       " 42\n",
       " 43\n",
       " 44\n",
       " 45\n",
       " 46\n",
       " 47\n",
       " 48\n",
       " 49\n",
       " 50"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(data2[!,:end_area])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T00:45:04.060000-05:00",
     "start_time": "2020-11-18T05:45:04.051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16-element Array{Int64,1}:\n",
       "  1\n",
       "  3\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 11\n",
       " 17\n",
       " 19\n",
       " 24\n",
       " 26\n",
       " 28\n",
       " 30\n",
       " 34\n",
       " 37\n",
       " 45"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(data2[!,:start_area])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
