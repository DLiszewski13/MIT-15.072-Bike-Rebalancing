{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore all the bs below, used it to build my stochastic models. I'll let you know when the important stuff begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "jan18 ALL GOOD\n",
      "50\n",
      "50\n",
      "50\n",
      "feb18 ALL GOOD\n",
      "50\n",
      "50\n",
      "50\n",
      "mar18 ALL GOOD\n",
      "50\n",
      "50\n",
      "50\n",
      "may18 ALL GOOD\n"
     ]
    }
   ],
   "source": [
    "for month in [\"jan18\",\"feb18\", \"mar18\", \"may18\"]\n",
    "    data1 = CSV.read(month*\"_filter_agg_scen1.csv\")\n",
    "    data2 = CSV.read(month*\"_filter_agg_scen2.csv\")\n",
    "    data3 = CSV.read(month*\"_filter_agg_scen3.csv\")\n",
    "    data4 = CSV.read(month*\"_filter_agg_scen4.csv\")\n",
    "    s1 = size(unique(data1[!,:start_area]),1)\n",
    "    println(s1)\n",
    "    s2 = size(unique(data2[!,:start_area]),1)\n",
    "    println(s2)\n",
    "    s3 = size(unique(data3[!,:start_area]),1)\n",
    "    println(s3)\n",
    "    s4 = size(unique(data4[!,:start_area]),1)\n",
    "    e1 = size(unique(data1[!,:end_area]),1)\n",
    "    e2 = size(unique(data1[!,:end_area]),1)\n",
    "    e3 = size(unique(data1[!,:end_area]),1)\n",
    "    e4 = size(unique(data1[!,:end_area]),1)\n",
    "    if s1 == s2 & s1 == s3 & s1 == s4 & s1 == e1 & s1 == e2 & s1 == e3 & s1 == e4\n",
    "        println(month*\" ALL GOOD\")\n",
    "    else\n",
    "        println(month*\" NOT GOOD\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Symbol,1}:\n",
       " :Column1              \n",
       " :Day                  \n",
       " :Hour                 \n",
       " :start_time_interval  \n",
       " :start_area           \n",
       " :end_area             \n",
       " :dep_flow             \n",
       " :hourly_dep_flow_total\n",
       " :hourly_dep_flow_pct  \n",
       " :allowed_flows        "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = CSV.read(\"may19_flows.csv\")\n",
    "names(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24-element Array{Int64,1}:\n",
       "  0\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(data1[!,:Hour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stations = Set(unique(data1[!,2]))\n",
    "end_stations = Set(unique(data1[!,3]))\n",
    "stations = collect(union(start_stations,end_stations))\n",
    "time_intervals = unique(data1[!,8])\n",
    "days = unique(data1[!,7]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sizes \n",
    "# m = total number of start station clusters\n",
    "m= size(stations,1)\n",
    "# n = total number of time windows\n",
    "n = size(time_intervals,1)\n",
    "# o = total number of days\n",
    "o = size(days,1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ride = 1.15\n",
    "c_bike = 345;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimize_distribution (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function optimize_distribution(data)\n",
    "    #initialize model\n",
    "    mod = Model(solver = GurobiSolver())\n",
    "\n",
    "    #decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o] >= 0,Int)\n",
    "\n",
    "    #objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o))\n",
    "\n",
    "\n",
    "    #constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o],x[i,t,l] - sum(d[i,j,t,l] for j=1:m) + sum(d[j,i,t,l] for j=1:m)-x[i,t+1,l]==0)\n",
    "    @constraint(mod,[d=1:o], sum(x[i,1,d] for i=1:m) == sum(x[i,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data,1)],d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]] <= data[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o],d[i,i,t,l]==0)\n",
    "    @constraint(mod,r_ride*sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o) - c_bike*sum(x[i,1,1] for i=1:m) >= -200000)\n",
    "\n",
    "\n",
    "\n",
    "    #solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    return sum(getvalue(x)[:,1,1]),getvalue(d),getobjectivevalue(mod)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 1870531 rows, 1836000 columns and 7088950 nonzeros\n",
      "Model fingerprint: 0x8997650e\n",
      "Variable types: 36000 continuous, 1800000 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 2e+05]\n",
      "Found heuristic solution: objective 1463.0000000\n",
      "Presolve removed 1852443 rows and 1746517 columns (presolve time = 5s) ...\n",
      "Presolve removed 1852443 rows and 1746528 columns\n",
      "Presolve time: 8.84s\n",
      "Presolved: 18088 rows, 89472 columns, 249573 nonzeros\n",
      "Variable types: 18058 continuous, 71414 integer (53421 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.4630000e+03   0.000000e+00   5.741041e+05     10s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 1.005090e+05, 7162 iterations, 0.28 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    100509.00000 100509.000  0.00%     -   10s\n",
      "\n",
      "Explored 0 nodes (7162 simplex iterations) in 10.45 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 100509 1463 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.005090000000e+05, best bound 1.005090000000e+05, gap 0.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(564.0, [-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 1.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 1.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "...\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0]\n",
       "\n",
       "[-0.0 0.0 … 0.0 0.0; 0.0 -0.0 … 0.0 0.0; … ; 0.0 0.0 … -0.0 0.0; 0.0 0.0 … 0.0 -0.0], 100509.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_distribution(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_distribution (generic function with 1 method)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function baseline_distribution(min_bikes,data)\n",
    "    uniform_dist = round(min_bikes/m)\n",
    "    mod = Model(solver = GurobiSolver())\n",
    "\n",
    "    #decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,l=1:o]>= 0)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o] >= 0)\n",
    "\n",
    "    #objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o))\n",
    "\n",
    "\n",
    "    #constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o],x[i,t,l] - sum(d[i,j,t,l] for j=1:m) + sum(d[j,i,t,l] for j=1:m)-x[i,t+1,l]==0)\n",
    "    @constraint(mod,[d=1:o], sum(x[i,1,d] for i=1:m) == sum(x[i,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data,1)],d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]] <= data[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o],d[i,i,t,l]==0)\n",
    "    @constraint(mod,[i=1:m,d=1:o],x[i,1,d]==uniform_dist)\n",
    "#     @constraint(mod,r_ride*sum(d[i,j,t,l] for i=1:m,j=1:m,t=1:n,l=1:o) - c_bike*sum(x[i,1,1] for i=1:m) >= -200000)\n",
    "\n",
    "    status = solve(mod)\n",
    "    \n",
    "    return getvalue(d)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything Above is Useless, The Real Shit Starts from Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions to run this baby:\n",
    "1. Make sure your files are named properly and that you have the csv files for all 4 scenarios for the months you want to run the model for. The file naming convention is \"mmmmyy_filter_agg_scenx.csv\" .For example, \"sept19_filter_agg_scen1.csv\"\n",
    "2. Every csv file should have the following columns with this exact naming convention: \"start_area\", \"end_area\", \"dep_flow\",\"Hour\"(0-23),\"Day\"(1-30/31).\n",
    "3. Run the functions below and then call the compute_everything function. The arguments to this function are \n",
    "    - a list of months you want to compute everything. For example - [\"sept19\",\"may18\",\"oct20\"]. Every month in this list should match the way the month is spelt in the dataset. \n",
    "    - The acceptable total loss per month (eg 200000)\n",
    "    - Operational Revenue - Operational costs (we discussed this number to be 1.15)\n",
    "    - Fixed cost of a bike (we discussed this to be 200)\n",
    "    - example call of the function - main_result = compute_everything([\"sept19\"],200000,1.15,200)\n",
    "4. The function ouputs the following:\n",
    "    - A CSV file with the optimal number of bikes per station per day for each month in the list of months\n",
    "    - A CSV file with the optimal model allowed flows for Scenario 1.\n",
    "    - A dataframe with the following information for each month (each row of the dataframe corresponds to one month in the list of months: Minimum Number of Bikes from the optimal model, Number of missed rides for the optimal and baseline scenarios, number of met rides for the optimal and baseline scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Gurobi, DataFrames, CSV, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_missed_rides (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_missed_rides(data,d)\n",
    "    missed_rides = [(data[i,:dep_flow]-d[data[i,:start_area],data[i,:end_area],data[i,:Hour]+1,data[i,:Day]])\n",
    "    for i=1:size(data,1)]\n",
    "    return sum(missed_rides)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_model (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### stochastic optimization model\n",
    "function stochastic_model(data1,data2,data3,data4,acceptable_loss,r_ride,c_bike)\n",
    "    \n",
    "    # m = total number of start station clusters\n",
    "    m= size(unique(data1[!,:start_area]),1)\n",
    "    # n = total number of time windows\n",
    "    n = size(unique(data1[!,:Hour]),1)\n",
    "    # o = total number of days\n",
    "    o = size(unique(data1[!,:Day]),1)\n",
    "    \n",
    "    #1. initialize model\n",
    "    \n",
    "    mod = Model(solver = GurobiSolver())\n",
    "    \n",
    "    #2. decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o,s=1:4]>= 0,Int)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o,s=1:4] >= 0,Int)\n",
    "    @variable(mod,max_stat,Int)\n",
    "    \n",
    "    #3. objective function\n",
    "    @objective(mod,Max,(sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4) - 0.0001*max_stat)\n",
    "    \n",
    "    \n",
    "    #4. constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o,s=1:4],x[i,t,l,s] - sum(d[i,j,t,l,s] for j=1:m) + sum(d[j,i,t,l,s] for j=1:m)-x[i,t+1,l,s]==0)\n",
    "    @constraint(mod,[d=1:o,s=1:4], sum(x[i,1,d,s] for i=1:m) == sum(x[i,1,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data1,1)],d[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day],1] <= data1[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data2,1)],d[data2[i,:start_area],data2[i,:end_area],data2[i,:Hour]+1,data2[i,:Day],2] <= data2[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data3,1)],d[data3[i,:start_area],data3[i,:end_area],data3[i,:Hour]+1,data3[i,:Day],3] <= data3[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data4,1)],d[data4[i,:start_area],data4[i,:end_area],data4[i,:Hour]+1,data4[i,:Day],4] <= data4[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o,s=1:4],d[i,i,t,l,s]==0)\n",
    "    @constraint(mod,r_ride*(sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4) - c_bike*sum(x[i,1,1,1] for i=1:m) >= -acceptable_loss)\n",
    "    @constraint(mod,[i=1:m,d=1:o,s=1:4], max_stat >= x[i,1,d,s])\n",
    "    \n",
    "    #5. solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    #6. Compute missed rides and average it for the 4 scenarios\n",
    "    missed_rides1 = compute_missed_rides(data1,getvalue(d)[:,:,:,:,1])\n",
    "    missed_rides2 = compute_missed_rides(data2,getvalue(d)[:,:,:,:,2])\n",
    "    missed_rides3 = compute_missed_rides(data3,getvalue(d)[:,:,:,:,3])\n",
    "    missed_rides4 = compute_missed_rides(data4,getvalue(d)[:,:,:,:,4])\n",
    "    avg_missed_rides = (missed_rides1+missed_rides2+missed_rides3+missed_rides4)/4\n",
    "    \n",
    "    #7. Compute number of rides met and average it for each scenario\n",
    "    avg_met_rides = getobjectivevalue(mod)\n",
    "    \n",
    "    #8. Input number of bikes per station per day into a dataframe (only for scenario 1)\n",
    "    bikes = getvalue(x)[:,:,:,1]\n",
    "    x_df = DataFrame(Station=Int[],Hour=Int[],Day=Int[],Num_Bikes=Int[])\n",
    "    for i=1:m\n",
    "        for j=1:n\n",
    "            for k=1:o\n",
    "                push!(x_df,[i,j,k,bikes[i,j,k]])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    \n",
    "    #9. Input allowed flows from scenario 1 into its dataframe (data1)\n",
    "    flows= getvalue(d)[:,:,:,:,1]\n",
    "    allowed_flows = []\n",
    "    for i in 1:size(data1,1)\n",
    "        append!(allowed_flows,flows[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day]])\n",
    "    end\n",
    "    data1[:allowed_flows] = allowed_flows\n",
    "    final_flows_data = data1[:,:]\n",
    "    \n",
    "   \n",
    "    \n",
    "    #10. return\n",
    "    return sum(getvalue(x)[:,1,1,1]),avg_missed_rides,avg_met_rides,x_df,final_flows_data\n",
    "    \n",
    "end\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_baseline (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stochastic_baseline(data1,data2,data3,data4,min_bikes,r_ride,c_bike)\n",
    "    # m = total number of start station clusters\n",
    "    m= size(unique(data1[!,:start_area]),1)\n",
    "    # n = total number of time windows\n",
    "    n = size(unique(data1[!,:Hour]),1)\n",
    "    # o = total number of days\n",
    "    o = size(unique(data1[!,:Day]),1)\n",
    "    \n",
    "    #1. uniform_dist = uniformly distributed number of bikes at each station\n",
    "    uniform_dist = round(min_bikes/m)\n",
    "    \n",
    "    #2. initialize model\n",
    "    \n",
    "    mod = Model(solver = GurobiSolver())\n",
    "    \n",
    "    #3. decision variables\n",
    "    @variable(mod,x[i=1:m,t=1:n,d=1:o,s=1:4]>= 0,Int)\n",
    "    @variable(mod,d[i=1:m,j=1:m,t=1:n,l=1:o,s=1:4] >= 0,Int)\n",
    "    \n",
    "    #4. objective function\n",
    "    @objective(mod,Max,sum(d[i,j,t,l,s] for i=1:m,j=1:m,t=1:n,l=1:o,s=1:4)/4)\n",
    "    \n",
    "    \n",
    "    #5. constraints\n",
    "    @constraint(mod,[i=1:m,t=1:n-1,l=1:o,s=1:4],x[i,t,l,s] - sum(d[i,j,t,l,s] for j=1:m) + sum(d[j,i,t,l,s] for j=1:m)-x[i,t+1,l,s]==0)\n",
    "    @constraint(mod,[d=1:o,s=1:4], sum(x[i,1,d,s] for i=1:m) == sum(x[i,1,1,1] for i=1:m))\n",
    "    @constraint(mod,[i=1:size(data1,1)],d[data1[i,:start_area],data1[i,:end_area],data1[i,:Hour]+1,data1[i,:Day],1] <= data1[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data2,1)],d[data2[i,:start_area],data2[i,:end_area],data2[i,:Hour]+1,data2[i,:Day],2] <= data2[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data3,1)],d[data3[i,:start_area],data3[i,:end_area],data3[i,:Hour]+1,data3[i,:Day],3] <= data3[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:size(data4,1)],d[data4[i,:start_area],data4[i,:end_area],data4[i,:Hour]+1,data4[i,:Day],4] <= data4[i,:dep_flow])\n",
    "    @constraint(mod,[i=1:m,t=1:n,l=1:o,s=1:4],d[i,i,t,l,s]==0)\n",
    "    @constraint(mod,[i=1:m,d=1:o,s=1:4],x[i,1,d,s]==uniform_dist)\n",
    "    \n",
    "    #6. solve model\n",
    "    status = solve(mod)\n",
    "    \n",
    "    #7. Compute missed rides and average it for the 4 scenarios\n",
    "    missed_rides1 = compute_missed_rides(data1,getvalue(d)[:,:,:,:,1])\n",
    "    missed_rides2 = compute_missed_rides(data2,getvalue(d)[:,:,:,:,2])\n",
    "    missed_rides3 = compute_missed_rides(data3,getvalue(d)[:,:,:,:,3])\n",
    "    missed_rides4 = compute_missed_rides(data4,getvalue(d)[:,:,:,:,4])\n",
    "    avg_missed_rides = (missed_rides1+missed_rides2+missed_rides3+missed_rides4)/4\n",
    "    \n",
    "    #8. Compute number of rides met and average it for each scenario\n",
    "    avg_met_rides = getobjectivevalue(mod)\n",
    "   \n",
    "    \n",
    "    #9. return\n",
    "    return avg_missed_rides,avg_met_rides\n",
    "    \n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function That Computes Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_everything (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_everything(month_list,acceptable_loss,r_ride,c_bike)\n",
    "    main_df = DataFrame(Month=String[],Min_Bikes=Int[],Missed_Optimal=Int[],\n",
    "    Missed_Baseline=Int[],Met_Optimal=Int[],Met_Baseline=Int[])\n",
    "    for i in month_list\n",
    "        \n",
    "        #read in datasets for the 4 scenarios\n",
    "        \n",
    "        data1 = CSV.read(\"$i\"*\"_filter_agg_scen1.csv\")\n",
    "        data2 = CSV.read(\"$i\"*\"_filter_agg_scen2.csv\")\n",
    "        data3 = CSV.read(\"$i\"*\"_filter_agg_scen3.csv\")\n",
    "        data4 = CSV.read(\"$i\"*\"_filter_agg_scen4.csv\")\n",
    "        \n",
    "        #define sizes - do it for one dataset because its the same for all 4 scenarios\n",
    "        \n",
    "        # m = total number of start station clusters\n",
    "        m= size(unique(data1[!,:start_area]),1)\n",
    "        # n = total number of time windows\n",
    "        n = size(unique(data1[!,:Hour]),1)\n",
    "        # o = total number of days\n",
    "        o = size(unique(data1[!,:Day]),1)\n",
    "        \n",
    "        #run optimal model and get outputs\n",
    "        optimal_solution = stochastic_model(data1,data2,data3,data4,acceptable_loss,r_ride,c_bike)\n",
    "        Min_Bikes = optimal_solution[1]\n",
    "        Missed_Optimal = optimal_solution[2]\n",
    "        Met_Optimal = optimal_solution[3]\n",
    "        CSV.write(\"$i\"*\"_bike_distribution.csv\",optimal_solution[4])\n",
    "#         CSV.write(\"$i\"*\"_flows.csv\",optimal_solution[5])\n",
    "        \n",
    "        #run baseline model and get outputs\n",
    "#         baseline_solution = stochastic_baseline(data1,data2,data3,data4,Min_Bikes,r_ride,c_bike)\n",
    "#         Missed_Baseline = baseline_solution[1]\n",
    "#         Met_Baseline = baseline_solution[2]\n",
    "        \n",
    "        \n",
    "#         #push values into main dataframe\n",
    "#         push!(main_df,[i,round(Min_Bikes),\n",
    "#                 round(Missed_Optimal),round(Missed_Baseline),round(Met_Optimal),round(Met_Baseline)])\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return main_df\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 7488121 rows, 7344001 columns and 28367950 nonzeros\n",
      "Model fingerprint: 0x276f7072\n",
      "Variable types: 0 continuous, 7344001 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-01, 2e+02]\n",
      "  Objective range  [1e-04, 2e-01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 2e+05]\n",
      "Found heuristic solution: objective 1286.5000000\n",
      "Presolve removed 1 rows and 0 columns (presolve time = 6s) ...\n",
      "Presolve removed 7347008 rows and 150000 columns (presolve time = 13s) ...\n",
      "Presolve removed 7348862 rows and 6959653 columns (presolve time = 19s) ...\n",
      "Presolve removed 7390195 rows and 7000986 columns (presolve time = 21s) ...\n",
      "Presolve removed 7396842 rows and 7010000 columns (presolve time = 26s) ...\n",
      "Presolve removed 7414945 rows and 7028374 columns (presolve time = 30s) ...\n",
      "Presolve removed 7415502 rows and 7029206 columns (presolve time = 39s) ...\n",
      "Presolve removed 7415502 rows and 7029206 columns (presolve time = 44s) ...\n",
      "Presolve removed 7415501 rows and 7029205 columns\n",
      "Presolve time: 43.66s\n",
      "Presolved: 72620 rows, 314796 columns, 886621 nonzeros\n",
      "Variable types: 0 continuous, 314796 integer (187713 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "Concurrent spin time: 0.31s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 8.634474e+04, 28205 iterations, 1.96 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    86344.743300 86344.7433  0.00%     -   52s\n",
      "\n",
      "Explored 0 nodes (28205 simplex iterations) in 55.19 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 86344.7 1286.5 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.634474330000e+04, best bound 8.634474330000e+04, gap 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `setindex!(df::DataFrame, v::AbstractVector, col_ind::ColumnIndex)` is deprecated, use `begin\n",
      "│     df[!, col_ind] = v\n",
      "│     df\n",
      "│ end` instead.\n",
      "│   caller = stochastic_model(::DataFrame, ::DataFrame, ::DataFrame, ::DataFrame, ::Int64, ::Float64, ::Int64) at In[3]:66\n",
      "└ @ Main ./In[3]:66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Month</th><th>Min_Bikes</th><th>Missed_Optimal</th><th>Missed_Baseline</th><th>Met_Optimal</th><th>Met_Baseline</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>0 rows × 6 columns</p></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Month & Min\\_Bikes & Missed\\_Optimal & Missed\\_Baseline & Met\\_Optimal & Met\\_Baseline\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "0×6 DataFrame\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_result = compute_everything([\"sep19\"],200000,1.15,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
